\documentclass[twoside,openright]{uva-bachelor-thesis}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[british]{babel}

%\usepackage[dutch]{babel}  % uncomment if you write in dutch
\usepackage{graphicx}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[style=ieee]{biblatex}
\addbibresource{thesis.bib}
\usepackage{lmodern}
%Enable for final compilation
%\usepackage[stretch=10]{microtype}
\usepackage{graphicx}



% Title Page
\title{Late Transmuxing:\\Improving caching in videostreaming}
\author{Jelte Fennema}
\supervisors{Dirk Griffioen (Unified Streaming), Robert Belleman (UvA)}
\signedby{Robert Belleman (UvA)}


\begin{document}
\maketitle

\begin{abstract}
\end{abstract}


\tableofcontents

\chapter{Introduction}
Streaming video reliably isn't an easy job. There are a couple of aspects that
can cause some problems. A significant problem is that there are different video
streaming protocols and not all of them are supported equally by all browsers.
This means a good video host should have its videos in a lot of different
formats to make sure they can be viewed in every browser. The video streaming
protocols have one thing in common, they all stream little video sections
instead of the whole file, because you can do that easiliy with
HTTP\autocite{http}. All this means that at some point the original video file
should be cut in smaller sections and those should be converted to the formats
that are needed.


\section{Traditional setups}
The most obvious setup is ofcourse generating these files once and then setting
up a file server that serves all these little files. This works but takes up
quite a bit of space since you're essentially storing the same video multiple
times. This issue can be solved by storing the raw video and converting it on
the fly to the format needed when a request comes in. This is what the Unified
Streaming software does.

However, in large streaming setups this is not enough for two reasons. The first
one is that the storage server might be far away from the viewer, which means
more time waiting before watching a video. The second one is that the storage
server can be easily overwhelmed with requests, because its just one server. A
simple solution to these problems is using a Content Distribution
Network\autocite{cdns} with reverse proxy caching\autocite{revproxy} nodes.
Those nodes forward the request to the storage server and cache the response. If
another request comes for the same content a node will just respond with the
response in its cache. This works quite good, since a small percentage of the
videos account for a large percentage of the views.
% For live streaming this also works fantastic since it's not even a whole
% video that is downloaded a lot, it is only the last part of that video.

The big problem of this setup is that, just like with the very first setup, it
stores the converted files instead of the raw files, only now in the cache
instead of the storage server. This has two downsides in this case. Again, the
server will contain the same content multiple times, only in this case the cache
server. The other downside, specific to this setup, is that the cache will also
request basically the same content from the storage. Those requests mean more
internal traffic and more waiting time for the viewer.

\section{Proposed setup}
The proposed improvement to this setup is the use of ``Late transmuxing''.
Instead of requesting the converted segments from the storage server, the cache
requests the raw content needed to create a segment. That raw content is then
cached and it can be used to generate responses for all the different formats.

\subsection{Theoretical improvements over the traditional setup}
In theory this has a couple of advantages over the traditional setup. The first
time a specific segment is request it should perform the same, but once that has
happened the same segment can be requested in another format and no network
traffic is generated. This is an advantage in itself, since network traffic can
be expensive at a large scale. However, it also means that there is no extra
latency caused by a request to the storage server and that latency can be
significant. Especially if the storage and the cache server are far located far
away from eachother geographically.

Another theoretical improvement is lowering the storage required on the cache
server to cache a segment. Instead of storing the same segment multiple times it
is now only stored in the raw format. This means that the cache gets filled up
less easily, which means it can cache more different segments.

\chapter{Background}
\section{Different streaming protocols}
At the moment there are four different streaming protocols in widespread use,
DASH (Dynamic Adaptive Streaming over HTTP) \autocite{dash}, ISS Smooth
Streaming \autocite{smooth}, HLS (HTTP Live Streaming) \autocite{hls} and HDS
(HTTP Dynamic Streaming) \autocite{hds}.

\section{HTTP Range Requests}
Range requests have been added to HTTP to serve parts of a file and not full
files.~\autocite{rangerequests}
\section{Caching}
\subsection{Caching range requests}
To cache range requests of any size, ranger \autocite{ranger} can be used.



\chapter{Implementation}
The server setup used consists of two servers, in this case virtual machines.
One that has the video files on disk, this will be called the storage server,
and one that serves as a reverse proxy, this will be called the proxy server.
The proxy server can also be called the cache server in the cases where it
caches proxied requests.

The client requests a specific segment of the video in a specific format, say
ISS. The storage server only contains the mp4 file of the video. At some point
in the server chain the segment needs to be generated from (part of) that mp4.

\section{Different configurations}
The servers contain a couple of different server application configurations and
do this segment generation at different stages. A common characteristic in all
these configurations is that the client connects with the proxy server and that
server will then request content the content it needs to fulfill this request
from the storage server.


\subsection{The CDN configuration}
A configuration that is currently heavily in use is the CDN configuration. In
this configuration the proxy server will receive the request for the segment
from the client and passes that exact reqest along to the storage server. The
storage server will then generate the segment from the mp4 and send the segment
back to the proxy server.  The proxy server will then send the response back to
the client, but it will also cache the response. That way, when a client
requests the same segment it will be able to serve it from its cache directly,
instead of requesting it from the storage server.


\includegraphics{cdn_diagram.pdf}

\subsection{The IsmProxyPass configuration}
Another configuration that is currently being used is the IsmProxyPass
configuration. This configuration does one thing quite different than the
CDN configuration. When the proxy server receives a request for a segment,
instead of passing it to the storage directly, it will send a series of range
requests to the storage server. Upon receiving one of those range requests, the
storage server will return the bytes from the mp4 file that are in the request
range. When the proxy server receives those bytes it will then use them to
generate the segment requested by the client. After this is done the segment
will be returned to the client. Another difference between this configuration
and the CDN configuration is that there is no caching involved


\includegraphics{ismproxy_diagram.pdf}

\subsection{The Late Transmuxing configuration}
The last configuration is the one this thesis is about. The late transmuxing
configuration. This configuration is a mix of the previous two configurations.
Stating it very simply, it is a version of the IsmProxyPass configuration with
caching built in. This is accomplished by running two different server
applications on the proxy server. A request of the client is initially handled
on the proxy server by Nginx. Nginx then passes the request along to Apache,
running on the same server. Apache then uses IsmProxyPass from the Unified
Streaming module to send the range requests mentioned in the previous
configuration.  However, instead of sending those requests to the storage server
directly, it sends them back to Nginx. Nginx then passes those requests along to
the storage server. The storage server will again respond with the byte ranges
requested.

When Nginx receives a response to one of its range requests we will want it to
cache that response. This can be done quite easily by using the range as part of
the cache key,~\autocite{nginxforum} which used to identify different items in
the cache. Normally this key only contains the URL that is requested. This way
of caching range requests can be very inefficient, because ranges that are not
the same, but do overlap will both be cached. For video streaming however, this
isn't a problem because the because the fragments are fixed, so the same ranges
will always be requested and overlaps in those ranges should be minimal.

Apart from caching the response Nginx will also return it to Apache. Apache will
then generate the originally requested segment and return that back to Nginx.
Nginx will then cache the segment and return it to the client.

\includegraphics{latetrans_diagram.pdf}
\subsubsection{The storage server}
\subsubsection{The caching server}
\section{Variations}

\chapter{Experiments}
\section{Setup}
\section{Results}

\chapter{Discussion}
\section{Future Work}
\chapter{Conclusions}


\printbibliography{}


\end{document}
